{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef894101-b3c3-4ae7-b0c4-a8e28e6e3a02",
   "metadata": {},
   "source": [
    "# Term Deposit Marketing\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e940ee-3443-4ecc-a91b-74889a8d5ea5",
   "metadata": {},
   "source": [
    "First, let's import the necessary libraries and load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064aad2e-738e-4dcd-8a42-e6ef8f5a098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_score,   recall_score \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cfd71f5-035c-42b8-ac6c-c1707417ae52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>y</th>\n",
       "      <th>recency</th>\n",
       "      <th>job_admin</th>\n",
       "      <th>...</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_tertiary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  default  balance  housing  loan  duration  campaign  y  recency  \\\n",
       "0  58.0        0   2143.0        1     0     261.0       1.0  0    241.0   \n",
       "1  44.0        0     29.0        1     0     151.0       1.0  0    241.0   \n",
       "2  33.0        0      2.0        1     1      76.0       1.0  0    241.0   \n",
       "3  47.0        0   1506.0        1     0      92.0       1.0  0    241.0   \n",
       "4  35.0        0    231.0        1     0     139.0       1.0  0    241.0   \n",
       "\n",
       "   job_admin  ...  job_services  job_student  job_technician  job_unemployed  \\\n",
       "0          0  ...             0            0               0               0   \n",
       "1          0  ...             0            0               1               0   \n",
       "2          0  ...             0            0               0               0   \n",
       "3          0  ...             0            0               0               0   \n",
       "4          0  ...             0            0               0               0   \n",
       "\n",
       "   marital_divorced  marital_married  marital_single  education_primary  \\\n",
       "0                 0                1               0                  0   \n",
       "1                 0                0               1                  0   \n",
       "2                 0                1               0                  0   \n",
       "3                 0                1               0                  0   \n",
       "4                 0                1               0                  0   \n",
       "\n",
       "   education_secondary  education_tertiary  \n",
       "0                    0                   1  \n",
       "1                    1                   0  \n",
       "2                    1                   0  \n",
       "3                    1                   0  \n",
       "4                    0                   1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data=pd.read_csv('../Data/processed_data.csv')\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2291d00d-0a01-4227-8302-2adeae8a7efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's scale our data using StandardScaler\n",
    "scaler=StandardScaler()\n",
    "\n",
    "X = final_data.drop(columns='y')\n",
    "y = final_data['y']\n",
    "X_scaled=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7afa8a65-ed11-43bc-bb07-1ac2497dfd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's first divide our data into training and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split( X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bac479",
   "metadata": {},
   "source": [
    "Our next step would be doing some feature selection based on correlation with the target column, F-score, mutual information and Random Forest importance. Let's create custom functions for these tasks. We'll use top 10 features for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65001650-3a50-4b06-801a-e06492a0894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need Column names map for these functions\n",
    "columns=X.columns\n",
    "column_mapping={i:col for i,col in enumerate(columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fff0a5b-77ff-4a6c-973c-efca0f0d4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "def select_features(X, y, column_mapping, k=10):\n",
    "\n",
    "    \n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X, columns=[column_mapping[i] for i in range(X.shape[1])])\n",
    "    \n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # F-score selection\n",
    "    f_selector = SelectKBest(f_classif, k=k)\n",
    "    f_selector.fit(X, y)\n",
    "    \n",
    "    # selected feature indices\n",
    "    selected_indices = f_selector.get_support(indices=True)\n",
    "    selected_feature_names = [feature_names[i] for i in selected_indices]\n",
    "\n",
    "    \n",
    "    f_selector_with_names = SelectKBest(f_classif, k=k)\n",
    "    f_selector_with_names.fit(X, y)  \n",
    "    \n",
    "    f_scores = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'f_score': f_selector.scores_,\n",
    "        'p_value': f_selector.pvalues_\n",
    "    })\n",
    "    \n",
    "\n",
    "    \n",
    "    return f_scores, f_selector, selected_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "728c20ce-a642-4c29-90e3-21c6d1f7ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Main analysis function\n",
    "def analyze_and_select_features(X_train, X_test, y_train,  column_mapping):\n",
    "    \n",
    "   if isinstance(X_train, np.ndarray):\n",
    "      X_train = pd.DataFrame(X_train, columns=[column_mapping[i] for i in range(X_train.shape[1])])\n",
    "      X_test = pd.DataFrame(X_test, columns=[column_mapping[i] for i in range(X_test.shape[1])])\n",
    "\n",
    "   # Select features\n",
    "   f_scores, f_selector, selected_feature_names = select_features(X_train, y_train, column_mapping)\n",
    "\n",
    "    \n",
    "   print(\"\\nTop 10 features by F-score:\")\n",
    "   print(f_scores.sort_values('f_score', ascending=False).head(10))\n",
    "    \n",
    "    \n",
    "    \n",
    "   # Apply feature selection\n",
    "   X_train_selected = pd.DataFrame( f_selector.transform(X_train),\n",
    "        columns=selected_feature_names,\n",
    "        index=X_train.index)\n",
    "   \n",
    "   X_test_selected = pd.DataFrame( f_selector.transform(X_test),\n",
    "        columns=selected_feature_names,\n",
    "        index=X_test.index)\n",
    "   \n",
    "   X_train_selected = pd.DataFrame(X_train_selected, columns=selected_feature_names)\n",
    "   X_test_selected = pd.DataFrame(X_test_selected, columns=selected_feature_names)\n",
    "\n",
    "   feature_importance_df = pd.DataFrame({\n",
    "        'feature': selected_feature_names,\n",
    "        'f_score': f_selector.scores_[f_selector.get_support()],\n",
    "        'p_value': f_selector.pvalues_[f_selector.get_support()]\n",
    "    })\n",
    "    \n",
    "   print(\"\\nSelected features with their importance scores:\")\n",
    "   print(feature_importance_df.sort_values('f_score', ascending=False))\n",
    "    \n",
    "   return X_train_selected, X_test_selected, f_selector, selected_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb859717-40a5-4e74-bf3a-5eaf44a2757c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 features by F-score:\n",
      "               feature      f_score       p_value\n",
      "5             duration  8682.668675  0.000000e+00\n",
      "20     marital_married   117.620525  2.344290e-27\n",
      "21      marital_single    90.538325  1.937514e-21\n",
      "3              housing    87.110770  1.090523e-20\n",
      "6             campaign    69.263064  8.957097e-17\n",
      "2              balance    69.189776  9.295446e-17\n",
      "16         job_student    62.064750  3.428810e-15\n",
      "7              recency    57.915406  2.811897e-14\n",
      "24  education_tertiary    53.153355  3.156782e-13\n",
      "9      job_blue-collar    34.019124  5.510042e-09\n",
      "\n",
      "Selected features with their importance scores:\n",
      "              feature      f_score       p_value\n",
      "2            duration  8682.668675  0.000000e+00\n",
      "7     marital_married   117.620525  2.344290e-27\n",
      "8      marital_single    90.538325  1.937514e-21\n",
      "1             housing    87.110770  1.090523e-20\n",
      "3            campaign    69.263064  8.957097e-17\n",
      "0             balance    69.189776  9.295446e-17\n",
      "6         job_student    62.064750  3.428810e-15\n",
      "4             recency    57.915406  2.811897e-14\n",
      "9  education_tertiary    53.153355  3.156782e-13\n",
      "5     job_blue-collar    34.019124  5.510042e-09\n",
      "\n",
      "Selected features:\n",
      "1. balance\n",
      "2. housing\n",
      "3. duration\n",
      "4. campaign\n",
      "5. recency\n",
      "6. job_blue-collar\n",
      "7. job_student\n",
      "8. marital_married\n",
      "9. marital_single\n",
      "10. education_tertiary\n",
      "\n",
      "Selected features with their importance scores:\n",
      "              feature      f_score       p_value\n",
      "2            duration  8682.668675  0.000000e+00\n",
      "7     marital_married   117.620525  2.344290e-27\n",
      "8      marital_single    90.538325  1.937514e-21\n",
      "1             housing    87.110770  1.090523e-20\n",
      "3            campaign    69.263064  8.957097e-17\n",
      "0             balance    69.189776  9.295446e-17\n",
      "6         job_student    62.064750  3.428810e-15\n",
      "4             recency    57.915406  2.811897e-14\n",
      "9  education_tertiary    53.153355  3.156782e-13\n",
      "5     job_blue-collar    34.019124  5.510042e-09\n"
     ]
    }
   ],
   "source": [
    "X_train_selected, X_test_selected, f_selector, selected_feature_names = analyze_and_select_features(X_train, X_test, y_train, column_mapping)\n",
    "\n",
    "# Print the selected feature names\n",
    "print(\"\\nSelected features:\")\n",
    "for i, feature in enumerate(selected_feature_names, 1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "\n",
    "# Create a DataFrame with selected features and their importance scores\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': selected_feature_names,\n",
    "    'f_score': f_selector.scores_[f_selector.get_support()],\n",
    "    'p_value': f_selector.pvalues_[f_selector.get_support()]\n",
    "})\n",
    "\n",
    "print(\"\\nSelected features with their importance scores:\")\n",
    "print(feature_importance_df.sort_values('f_score', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29662c4b-920a-43f2-a068-6b4062e78fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>recency</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_student</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>education_tertiary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.516390</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>-0.321329</td>\n",
       "      <td>-0.714401</td>\n",
       "      <td>0.547098</td>\n",
       "      <td>-0.555729</td>\n",
       "      <td>-0.115557</td>\n",
       "      <td>0.801097</td>\n",
       "      <td>-0.611945</td>\n",
       "      <td>-0.636844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.626891</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>0.096662</td>\n",
       "      <td>0.106001</td>\n",
       "      <td>-0.010654</td>\n",
       "      <td>-0.555729</td>\n",
       "      <td>-0.115557</td>\n",
       "      <td>-1.248288</td>\n",
       "      <td>1.634133</td>\n",
       "      <td>-0.636844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.224973</td>\n",
       "      <td>-1.234229</td>\n",
       "      <td>1.229281</td>\n",
       "      <td>0.106001</td>\n",
       "      <td>-2.199833</td>\n",
       "      <td>1.799440</td>\n",
       "      <td>-0.115557</td>\n",
       "      <td>0.801097</td>\n",
       "      <td>-0.611945</td>\n",
       "      <td>-0.636844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.548536</td>\n",
       "      <td>0.810223</td>\n",
       "      <td>-0.820221</td>\n",
       "      <td>-0.714401</td>\n",
       "      <td>0.337941</td>\n",
       "      <td>-0.555729</td>\n",
       "      <td>-0.115557</td>\n",
       "      <td>-1.248288</td>\n",
       "      <td>1.634133</td>\n",
       "      <td>-0.636844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.515385</td>\n",
       "      <td>-1.234229</td>\n",
       "      <td>0.141607</td>\n",
       "      <td>-0.714401</td>\n",
       "      <td>-0.317418</td>\n",
       "      <td>-0.555729</td>\n",
       "      <td>-0.115557</td>\n",
       "      <td>0.801097</td>\n",
       "      <td>-0.611945</td>\n",
       "      <td>1.570242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    balance   housing  duration  campaign   recency  job_blue-collar  \\\n",
       "0 -0.516390  0.810223 -0.321329 -0.714401  0.547098        -0.555729   \n",
       "1 -0.626891  0.810223  0.096662  0.106001 -0.010654        -0.555729   \n",
       "2  0.224973 -1.234229  1.229281  0.106001 -2.199833         1.799440   \n",
       "3 -0.548536  0.810223 -0.820221 -0.714401  0.337941        -0.555729   \n",
       "4 -0.515385 -1.234229  0.141607 -0.714401 -0.317418        -0.555729   \n",
       "\n",
       "   job_student  marital_married  marital_single  education_tertiary  \n",
       "0    -0.115557         0.801097       -0.611945           -0.636844  \n",
       "1    -0.115557        -1.248288        1.634133           -0.636844  \n",
       "2    -0.115557         0.801097       -0.611945           -0.636844  \n",
       "3    -0.115557        -1.248288        1.634133           -0.636844  \n",
       "4    -0.115557         0.801097       -0.611945            1.570242  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc7b8a3",
   "metadata": {},
   "source": [
    "Before we start our modeling process, let's take a look at the distribution of the values for our target column value distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee019d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    36886\n",
       "1     2879\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39f6763",
   "metadata": {},
   "source": [
    "Our majority class is almost 13 times bigger than the minority class. This would affect our models performance, therefore let's address that first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d446ef9a",
   "metadata": {},
   "source": [
    "Let's try NearMiss-3 undersampling method for our highly imabalanced dataset, which selects k nearest majority samples for each minority sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d9463b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm3 = NearMiss(version=3, n_neighbors=3)\n",
    "X_train_balanced, y_train_balanced = nm3.fit_resample(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3891ac22-8fcf-47da-af48-32cec543a7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    2284\n",
       "1    2284\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_balanced.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f7c9ce",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762b53d",
   "metadata": {},
   "source": [
    "Now we'll try 3 ML algorithms for our data: Logistic Regression, Random Forest and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e254f37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Training Accuracy: 0.628\n",
      "Test Accuracy: 0.845\n",
      "F1 Score: 0.384\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      7358\n",
      "           1       0.27      0.65      0.38       595\n",
      "\n",
      "    accuracy                           0.84      7953\n",
      "   macro avg       0.62      0.75      0.65      7953\n",
      "weighted avg       0.92      0.84      0.87      7953\n",
      "\n",
      "\n",
      "Random Forest Results:\n",
      "Training Accuracy: 1.000\n",
      "Test Accuracy: 0.719\n",
      "F1 Score: 0.277\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.72      0.83      7358\n",
      "           1       0.17      0.72      0.28       595\n",
      "\n",
      "    accuracy                           0.72      7953\n",
      "   macro avg       0.57      0.72      0.55      7953\n",
      "weighted avg       0.91      0.72      0.78      7953\n",
      "\n",
      "\n",
      "XGBoost Results:\n",
      "Training Accuracy: 0.951\n",
      "Test Accuracy: 0.793\n",
      "F1 Score: 0.339\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88      7358\n",
      "           1       0.22      0.71      0.34       595\n",
      "\n",
      "    accuracy                           0.79      7953\n",
      "   macro avg       0.60      0.76      0.61      7953\n",
      "weighted avg       0.92      0.79      0.84      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(random_state=42, max_iter=5000)\n",
    "lr.fit(X_train_balanced, y_train_balanced)\n",
    "lr_pred = lr.predict(X_test_selected)\n",
    "lr_train_score = lr.score(X_train_balanced, y_train_balanced)\n",
    "lr_test_score = lr.score(X_test_selected, y_test)\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"Training Accuracy: {lr_train_score:.3f}\")\n",
    "print(f\"Test Accuracy: {lr_test_score:.3f}\")\n",
    "print(f\"F1 Score: {lr_f1:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, lr_pred))\n",
    "\n",
    "# 2. Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_balanced, y_train_balanced)\n",
    "rf_pred = rf.predict(X_test_selected)\n",
    "rf_train_score = rf.score(X_train_balanced, y_train_balanced)\n",
    "rf_test_score = rf.score(X_test_selected, y_test)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(f\"Training Accuracy: {rf_train_score:.3f}\")\n",
    "print(f\"Test Accuracy: {rf_test_score:.3f}\")\n",
    "print(f\"F1 Score: {rf_f1:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_pred))\n",
    "\n",
    "# 3. XGBoost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "xgb.fit(X_train_balanced, y_train_balanced)\n",
    "xgb_pred = xgb.predict(X_test_selected)\n",
    "xgb_train_score = xgb.score(X_train_balanced, y_train_balanced)\n",
    "xgb_test_score = xgb.score(X_test_selected, y_test)\n",
    "xgb_f1 = f1_score(y_test, xgb_pred)\n",
    "\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(f\"Training Accuracy: {xgb_train_score:.3f}\")\n",
    "print(f\"Test Accuracy: {xgb_test_score:.3f}\")\n",
    "print(f\"F1 Score: {xgb_f1:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9768b5",
   "metadata": {},
   "source": [
    "It seems like all 3 models are having hard time capturing our minority class examples, which is resulting very low precision results. Let's try to do some parameter tuning to find the limit of these algorithms on our data, after which we'll try to address our data imbalance using other techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c996625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n",
      "\n",
      "Random Forest Results:\n",
      "Best Parameters:\n",
      "{'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "\n",
      "Best Cross-validation F1 Score: 0.669\n",
      "\n",
      "Random Forest Test Set Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.73      0.83      7358\n",
      "           1       0.18      0.74      0.29       595\n",
      "\n",
      "    accuracy                           0.73      7953\n",
      "   macro avg       0.58      0.73      0.56      7953\n",
      "weighted avg       0.91      0.73      0.79      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Random Forest results\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_rf.best_params_)\n",
    "print(f\"\\nBest Cross-validation F1 Score: {grid_rf.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best Random Forest on test set\n",
    "best_rf = grid_rf.best_estimator_\n",
    "best_rf_pred = best_rf.predict(X_test_selected)\n",
    "print(\"\\nRandom Forest Test Set Results:\")\n",
    "print(classification_report(y_test, best_rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84f03bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "Fitting 5 folds for each of 2187 candidates, totalling 10935 fits\n",
      "\n",
      "XGBoost Results:\n",
      "Best Parameters:\n",
      "{'colsample_bytree': 0.8, 'gamma': 0.5, 'learning_rate': 0.001, 'max_depth': 12, 'min_child_weight': 10, 'n_estimators': 200, 'subsample': 0.6}\n",
      "\n",
      "Best Cross-validation F1 Score: 0.698\n",
      "\n",
      "XGBoost Test Set Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.75      0.85      7358\n",
      "           1       0.20      0.77      0.32       595\n",
      "\n",
      "    accuracy                           0.75      7953\n",
      "   macro avg       0.59      0.76      0.58      7953\n",
      "weighted avg       0.92      0.75      0.81      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# parameter grid for XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [50, 200, 500],\n",
    "    'max_depth': [2, 6, 12],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 5, 10],\n",
    "    'gamma': [0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    XGBClassifier(random_state=42),\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "grid_xgb.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Print XGBoost results\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_xgb.best_params_)\n",
    "print(f\"\\nBest Cross-validation F1 Score: {grid_xgb.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best XGBoost on test set\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "best_xgb_pred = best_xgb.predict(X_test_selected)\n",
    "print(\"\\nXGBoost Test Set Results:\")\n",
    "print(classification_report(y_test, best_xgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff0751",
   "metadata": {},
   "source": [
    "It seems that even with tuned hyperparameters, NearMiss 3 was not able to deliver acceptable results. Let's try oversampling techniques this time since the small size of the data might be the main reason of low metrics on minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "057457c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying SMOTE...\n",
      "SMOTE Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94      7358\n",
      "           1       0.42      0.85      0.56       595\n",
      "\n",
      "    accuracy                           0.90      7953\n",
      "   macro avg       0.70      0.88      0.75      7953\n",
      "weighted avg       0.94      0.90      0.92      7953\n",
      "\n",
      "\n",
      "Trying ADASYN...\n",
      "ADASYN Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94      7358\n",
      "           1       0.39      0.86      0.54       595\n",
      "\n",
      "    accuracy                           0.89      7953\n",
      "   macro avg       0.69      0.88      0.74      7953\n",
      "weighted avg       0.94      0.89      0.91      7953\n",
      "\n",
      "\n",
      "Trying SMOTEENN...\n",
      "SMOTEENN Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91      7358\n",
      "           1       0.32      0.92      0.48       595\n",
      "\n",
      "    accuracy                           0.85      7953\n",
      "   macro avg       0.66      0.88      0.70      7953\n",
      "weighted avg       0.94      0.85      0.88      7953\n",
      "\n",
      "\n",
      "Trying SMOTETomek...\n",
      "SMOTETomek Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94      7358\n",
      "           1       0.42      0.85      0.56       595\n",
      "\n",
      "    accuracy                           0.90      7953\n",
      "   macro avg       0.70      0.88      0.75      7953\n",
      "weighted avg       0.94      0.90      0.92      7953\n",
      "\n",
      "\n",
      "Comparison of Sampling Techniques:\n",
      "            F1 Score  Accuracy  Precision    Recall\n",
      "SMOTE       0.559822  0.900541   0.418469  0.845378\n",
      "ADASYN      0.539968  0.890733   0.394127  0.857143\n",
      "SMOTEENN    0.479650  0.850497   0.324260  0.921008\n",
      "SMOTETomek  0.562222  0.900918   0.419917  0.850420\n"
     ]
    }
   ],
   "source": [
    "sampling_techniques = {\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'ADASYN': ADASYN(random_state=42),\n",
    "    'SMOTEENN': SMOTEENN(random_state=42),\n",
    "    'SMOTETomek': SMOTETomek(random_state=42)\n",
    "}\n",
    "\n",
    "# Try each sampling technique with XGBoost\n",
    "results = {}\n",
    "for name, sampler in sampling_techniques.items():\n",
    "    print(f\"\\nTrying {name}...\")\n",
    "    \n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X_train_selected, y_train)\n",
    "    \n",
    "    # Train XGBoost with best parameters\n",
    "    xgb = XGBClassifier(**grid_xgb.best_params_, random_state=42)\n",
    "    xgb.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test_selected)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    results[name] = {\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"{name} Results:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compare results\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nComparison of Sampling Techniques:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93095ea1",
   "metadata": {},
   "source": [
    "It seems that SMOTETomek performed the best, let's try to build a new model based on this sampling technique. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab25935",
   "metadata": {},
   "source": [
    "We'll use the following technique: </br> Create a ranked list of our features, using the function from earlier and then starting from 1 feature add features one by one to see how they affect the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3743726d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sirak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:783: UserWarning: k=26 is greater than n_features=25. All the features will be returned.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sirak\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:783: UserWarning: k=26 is greater than n_features=25. All the features will be returned.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with 1 features: ['age']\n",
      "\n",
      "Results with 1 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.73      0.82      7358\n",
      "           1       0.10      0.35      0.15       595\n",
      "\n",
      "    accuracy                           0.70      7953\n",
      "   macro avg       0.51      0.54      0.49      7953\n",
      "weighted avg       0.87      0.70      0.77      7953\n",
      "\n",
      "Trying with 2 features: ['age', 'default']\n",
      "\n",
      "Results with 2 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.66      0.77      7358\n",
      "           1       0.09      0.43      0.15       595\n",
      "\n",
      "    accuracy                           0.64      7953\n",
      "   macro avg       0.51      0.54      0.46      7953\n",
      "weighted avg       0.87      0.64      0.73      7953\n",
      "\n",
      "Trying with 3 features: ['age', 'default', 'balance']\n",
      "\n",
      "Results with 3 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.80      7358\n",
      "           1       0.10      0.42      0.17       595\n",
      "\n",
      "    accuracy                           0.68      7953\n",
      "   macro avg       0.52      0.56      0.49      7953\n",
      "weighted avg       0.88      0.68      0.76      7953\n",
      "\n",
      "Trying with 4 features: ['age', 'default', 'balance', 'housing']\n",
      "\n",
      "Results with 4 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81      7358\n",
      "           1       0.10      0.41      0.16       595\n",
      "\n",
      "    accuracy                           0.69      7953\n",
      "   macro avg       0.52      0.56      0.49      7953\n",
      "weighted avg       0.87      0.69      0.76      7953\n",
      "\n",
      "Trying with 5 features: ['age', 'default', 'balance', 'housing', 'loan']\n",
      "\n",
      "Results with 5 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.70      0.80      7358\n",
      "           1       0.10      0.42      0.16       595\n",
      "\n",
      "    accuracy                           0.68      7953\n",
      "   macro avg       0.52      0.56      0.48      7953\n",
      "weighted avg       0.87      0.68      0.75      7953\n",
      "\n",
      "Trying with 6 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration']\n",
      "\n",
      "Results with 6 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      7358\n",
      "           1       0.34      0.77      0.47       595\n",
      "\n",
      "    accuracy                           0.87      7953\n",
      "   macro avg       0.66      0.83      0.70      7953\n",
      "weighted avg       0.93      0.87      0.89      7953\n",
      "\n",
      "Trying with 7 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign']\n",
      "\n",
      "Results with 7 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93      7358\n",
      "           1       0.36      0.76      0.49       595\n",
      "\n",
      "    accuracy                           0.88      7953\n",
      "   macro avg       0.67      0.82      0.71      7953\n",
      "weighted avg       0.93      0.88      0.90      7953\n",
      "\n",
      "Trying with 8 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency']\n",
      "\n",
      "Results with 8 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.94      7358\n",
      "           1       0.42      0.86      0.57       595\n",
      "\n",
      "    accuracy                           0.90      7953\n",
      "   macro avg       0.71      0.88      0.76      7953\n",
      "weighted avg       0.95      0.90      0.92      7953\n",
      "\n",
      "Trying with 9 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin']\n",
      "\n",
      "Results with 9 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      7358\n",
      "           1       0.42      0.86      0.56       595\n",
      "\n",
      "    accuracy                           0.90      7953\n",
      "   macro avg       0.70      0.88      0.75      7953\n",
      "weighted avg       0.94      0.90      0.91      7953\n",
      "\n",
      "Trying with 10 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar']\n",
      "\n",
      "Results with 10 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.43      0.85      0.57       595\n",
      "\n",
      "    accuracy                           0.90      7953\n",
      "   macro avg       0.71      0.88      0.76      7953\n",
      "weighted avg       0.94      0.90      0.92      7953\n",
      "\n",
      "Trying with 11 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur']\n",
      "\n",
      "Results with 11 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.44      0.85      0.58       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.88      0.76      7953\n",
      "weighted avg       0.95      0.91      0.92      7953\n",
      "\n",
      "Trying with 12 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid']\n",
      "\n",
      "Results with 12 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.43      0.85      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.88      0.76      7953\n",
      "weighted avg       0.95      0.91      0.92      7953\n",
      "\n",
      "Trying with 13 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management']\n",
      "\n",
      "Results with 13 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.43      0.84      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.88      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 14 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired']\n",
      "\n",
      "Results with 14 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.43      0.84      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.87      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 15 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed']\n",
      "\n",
      "Results with 15 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.43      0.84      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.87      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 16 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services']\n",
      "\n",
      "Results with 16 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95      7358\n",
      "           1       0.44      0.82      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.87      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 17 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student']\n",
      "\n",
      "Results with 17 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      7358\n",
      "           1       0.45      0.82      0.58       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.72      0.87      0.77      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 18 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician']\n",
      "\n",
      "Results with 18 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      7358\n",
      "           1       0.44      0.82      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.87      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 19 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed']\n",
      "\n",
      "Results with 19 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      7358\n",
      "           1       0.44      0.81      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.86      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 20 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'marital_divorced']\n",
      "\n",
      "Results with 20 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.43      0.84      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.87      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 21 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'marital_divorced', 'marital_married']\n",
      "\n",
      "Results with 21 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      7358\n",
      "           1       0.45      0.83      0.58       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.72      0.87      0.77      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 22 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'marital_divorced', 'marital_married', 'marital_single']\n",
      "\n",
      "Results with 22 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      7358\n",
      "           1       0.45      0.81      0.58       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.72      0.86      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 23 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary']\n",
      "\n",
      "Results with 23 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.44      0.83      0.58       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.87      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 24 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary', 'education_secondary']\n",
      "\n",
      "Results with 24 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95      7358\n",
      "           1       0.44      0.84      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.87      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n",
      "Trying with 25 features: ['age', 'default', 'balance', 'housing', 'loan', 'duration', 'campaign', 'recency', 'job_admin', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary', 'education_secondary', 'education_tertiary']\n",
      "\n",
      "Results with 25 features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      7358\n",
      "           1       0.44      0.83      0.57       595\n",
      "\n",
      "    accuracy                           0.91      7953\n",
      "   macro avg       0.71      0.87      0.76      7953\n",
      "weighted avg       0.94      0.91      0.92      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_scores, f_selector, selected_feature_names = select_features(X, y, column_mapping, k=26)\n",
    "\n",
    "feature_addition_results = []\n",
    "\n",
    "# Adding features one by one\n",
    "for i in range(1, len(selected_feature_names) + 1):\n",
    "    current_features = selected_feature_names[:i]\n",
    "\n",
    "    print(f\"Trying with {i} features: {current_features}\")\n",
    "\n",
    "    feature_indices = [list(selected_feature_names).index(feature) for feature in current_features]\n",
    "\n",
    "    X_train_current = X_train[:, feature_indices]\n",
    "    X_test_current = X_test[:, feature_indices]\n",
    "    \n",
    "    \n",
    "    # Using NearMiss-3 again to handle imbalance\n",
    "    ST = SMOTETomek(random_state=42)\n",
    "    X_st, y_st = ST.fit_resample(X_train_current, y_train)\n",
    "\n",
    "    \n",
    "    # Train XGBoost\n",
    "    xgb = XGBClassifier(**grid_xgb.best_params_, random_state=42)\n",
    "    xgb.fit(X_st, y_st)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = xgb.predict(X_test_current)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    current_results = {\n",
    "        'n_features': i,\n",
    "        'features': current_features,\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    feature_addition_results.append(current_results)\n",
    "    \n",
    "    print(f\"\\nResults with {i} features:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(feature_addition_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a23b3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Feature Combination:\n",
      "Number of features: 17\n",
      "F1 Score: 0.582\n",
      "\n",
      "Features:\n",
      "- age\n",
      "- default\n",
      "- balance\n",
      "- housing\n",
      "- loan\n",
      "- duration\n",
      "- campaign\n",
      "- recency\n",
      "- job_admin\n",
      "- job_blue-collar\n",
      "- job_entrepreneur\n",
      "- job_housemaid\n",
      "- job_management\n",
      "- job_retired\n",
      "- job_self-employed\n",
      "- job_services\n",
      "- job_student\n",
      "\n",
      "Detailed Results:\n",
      " n_features  F1 Score  Accuracy  Precision   Recall\n",
      "          1  0.151025  0.703131   0.096066 0.352941\n",
      "          2  0.150730  0.641519   0.091600 0.425210\n",
      "          3  0.166777  0.683390   0.103832 0.423529\n",
      "          4  0.164761  0.687665   0.102984 0.411765\n",
      "          5  0.164428  0.679241   0.102116 0.421849\n",
      "          6  0.469388  0.869232   0.336996 0.773109\n",
      "          7  0.485730  0.879920   0.357369 0.757983\n",
      "          8  0.569052  0.902301   0.424669 0.862185\n",
      "          9  0.559648  0.899283   0.415850 0.855462\n",
      "         10  0.568683  0.904061   0.428450 0.845378\n",
      "         11  0.580240  0.907582   0.439446 0.853782\n",
      "         12  0.572887  0.905319   0.432363 0.848739\n",
      "         13  0.570451  0.905319   0.431779 0.840336\n",
      "         14  0.569954  0.905696   0.432550 0.835294\n",
      "         15  0.569954  0.905696   0.432550 0.835294\n",
      "         16  0.568754  0.907331   0.436266 0.816807\n",
      "         17  0.582490  0.911857   0.451107 0.821849\n",
      "         18  0.571765  0.908462   0.439819 0.816807\n",
      "         19  0.571938  0.909468   0.442502 0.808403\n",
      "         20  0.571922  0.906450   0.434821 0.835294\n",
      "         21  0.581217  0.910851   0.448087 0.826891\n",
      "         22  0.575359  0.910726   0.446611 0.808403\n",
      "         23  0.575916  0.908336   0.440391 0.831933\n",
      "         24  0.574235  0.907331   0.437500 0.835294\n",
      "         25  0.573933  0.908336   0.439964 0.825210\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot F1 score vs number of features\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(results_df['n_features'], results_df['F1 Score'], marker='o')\n",
    "plt.title('F1 Score vs Number of Features')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "# Print best feature combination\n",
    "best_result = results_df.loc[results_df['F1 Score'].nlargest().index[0]]\n",
    "print(\"\\nBest Feature Combination:\")\n",
    "print(f\"Number of features: {best_result['n_features']}\")\n",
    "print(f\"F1 Score: {best_result['F1 Score']:.3f}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for feature in best_result['features']:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "# Print detailed results table\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(results_df[['n_features', 'F1 Score', 'Accuracy', 'Precision', 'Recall']].to_string(index=False))\n",
    "\n",
    "# Save the best feature combination\n",
    "best_features = best_result['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d775074",
   "metadata": {},
   "source": [
    "It looks like 17 features show the best f1 score on our XGBoost model. Now let's combine all of our findings and train our 17 feature data on the following models: Logistic Regression, Decision Trees, Random Forest, XGBoost, KNN and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7abab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train, columns=selected_feature_names)\n",
    "X_test_df = pd.DataFrame(X_test, columns=selected_feature_names)\n",
    "\n",
    "X_train_current = X_train_df[best_features]\n",
    "X_test_current = X_test_df[best_features]\n",
    "\n",
    "ST = SMOTETomek(random_state=42)\n",
    "X_train_m, y_train_m = ST.fit_resample(X_train_current, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6a67172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Logistic Regression Results:\n",
      "Best Parameters:\n",
      "{'C': 0.001, 'class_weight': 'balanced', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "\n",
      "Best Cross-validation F1 Score: 0.828\n",
      "\n",
      "Logistic Regression Test Set Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.91      7358\n",
      "           1       0.29      0.80      0.43       595\n",
      "\n",
      "    accuracy                           0.84      7953\n",
      "   macro avg       0.64      0.82      0.67      7953\n",
      "weighted avg       0.93      0.84      0.87      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'class_weight': ['balanced', None] \n",
    "}\n",
    "\n",
    "grid_lr = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    param_grid_lr,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training Logistic Regression...\")\n",
    "grid_lr.fit(X_train_m, y_train_m)\n",
    "\n",
    "# Print Logistic Regression results\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_lr.best_params_)\n",
    "print(f\"\\nBest Cross-validation F1 Score: {grid_lr.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best Logistic Regression on test set\n",
    "best_lr = grid_lr.best_estimator_\n",
    "best_lr_pred = best_lr.predict(X_test_current)\n",
    "\n",
    "print(\"\\nLogistic Regression Test Set Results:\")\n",
    "print(classification_report(y_test, best_lr_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10138385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree...\n",
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "\n",
      "Decision Tree Results:\n",
      "Best Parameters:\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "\n",
      "Best Cross-validation F1 Score: 0.933\n",
      "\n",
      "Decision Tree Test Set Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95      7358\n",
      "           1       0.39      0.57      0.46       595\n",
      "\n",
      "    accuracy                           0.90      7953\n",
      "   macro avg       0.68      0.75      0.70      7953\n",
      "weighted avg       0.92      0.90      0.91      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 7, 9, 11, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': ['balanced', None]  \n",
    "}\n",
    "\n",
    "grid_dt = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid_dt,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training Decision Tree...\")\n",
    "grid_dt.fit(X_train_m, y_train_m)\n",
    "\n",
    "# Print Decision Tree results\n",
    "print(\"\\nDecision Tree Results:\")\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_dt.best_params_)\n",
    "print(f\"\\nBest Cross-validation F1 Score: {grid_dt.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best Decision Tree on test set\n",
    "best_dt = grid_dt.best_estimator_\n",
    "best_dt_pred = best_dt.predict(X_test_current)\n",
    "\n",
    "print(\"\\nDecision Tree Test Set Results:\")\n",
    "print(classification_report(y_test, best_dt_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2395320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "\n",
      "Random Forest Results:\n",
      "Best Parameters:\n",
      "{'max_depth': None, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "\n",
      "Best Cross-validation F1 Score: 0.957\n",
      "\n",
      "Random Forest Test Set Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      7358\n",
      "           1       0.48      0.68      0.56       595\n",
      "\n",
      "    accuracy                           0.92      7953\n",
      "   macro avg       0.72      0.81      0.76      7953\n",
      "weighted avg       0.94      0.92      0.93      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [5, 10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_grid_rf,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "grid_rf.fit(X_train_m, y_train_m)\n",
    "\n",
    "# Print Random Forest results\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_rf.best_params_)\n",
    "print(f\"\\nBest Cross-validation F1 Score: {grid_rf.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best Random Forest on test set\n",
    "best_rf = grid_rf.best_estimator_\n",
    "best_rf_pred = best_rf.predict(X_test_current)\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest Test Set Results:\")\n",
    "print(classification_report(y_test, best_rf_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ec3b168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "\n",
      "KNN Results:\n",
      "Best Parameters:\n",
      "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "\n",
      "Best Cross-validation F1 Score: 0.948\n",
      "\n",
      "KNN Test Set Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      7358\n",
      "           1       0.35      0.63      0.45       595\n",
      "\n",
      "    accuracy                           0.88      7953\n",
      "   macro avg       0.66      0.77      0.69      7953\n",
      "weighted avg       0.92      0.88      0.90      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(\n",
    "    KNeighborsClassifier(),\n",
    "    param_grid_knn,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training KNN...\")\n",
    "grid_knn.fit(X_train_m, y_train_m)\n",
    "\n",
    "# Print KNN results\n",
    "print(\"\\nKNN Results:\")\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_knn.best_params_)\n",
    "print(f\"\\nBest Cross-validation F1 Score: {grid_knn.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best KNN on test set\n",
    "best_knn = grid_knn.best_estimator_\n",
    "best_knn_pred = best_knn.predict(X_test_current)\n",
    "\n",
    "\n",
    "print(\"\\nKNN Test Set Results:\")\n",
    "print(classification_report(y_test, best_knn_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56116216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100], \n",
    "    'kernel': ['linear', 'rbf'], \n",
    "    'gamma': ['scale', 0.1, 0.01]\n",
    "}\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "    SVC(random_state=42, probability=True),\n",
    "    param_grid_svm,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training SVM...\")\n",
    "grid_svm.fit(X_train_m, y_train_m)\n",
    "\n",
    "# Print SVM results\n",
    "print(\"\\nSVM Results:\")\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_svm.best_params_)\n",
    "print(f\"\\nBest Cross-validation F1 Score: {grid_svm.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best SVM on test set\n",
    "best_svm = grid_svm.best_estimator_\n",
    "best_svm_pred = best_svm.predict(X_test_current)\n",
    "\n",
    "\n",
    "print(\"\\nSVM Test Set Results:\")\n",
    "print(classification_report(y_test, best_svm_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5707ffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "XGBoost Results:\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 300, 'subsample': 0.8}\n",
      "\n",
      "Best Cross-validation F1 Score: 0.956\n",
      "\n",
      "XGBoost Test Set Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      7358\n",
      "           1       0.51      0.57      0.54       595\n",
      "\n",
      "    accuracy                           0.93      7953\n",
      "   macro avg       0.74      0.77      0.75      7953\n",
      "weighted avg       0.93      0.93      0.93      7953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    XGBClassifier(random_state=42),\n",
    "    param_grid_xgb,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost...\")\n",
    "grid_xgb.fit(X_train_m, y_train_m)\n",
    "\n",
    "# Print XGBoost results\n",
    "print(\"\\nXGBoost Results:\")\n",
    "print(\"Best Parameters:\")\n",
    "print(grid_xgb.best_params_)\n",
    "print(f\"\\nBest Cross-validation F1 Score: {grid_xgb.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate best XGBoost on test set\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "best_xgb_pred = best_xgb.predict(X_test_current)\n",
    "\n",
    "\n",
    "print(\"\\nXGBoost Test Set Results:\")\n",
    "print(classification_report(y_test, best_xgb_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c976ef",
   "metadata": {},
   "source": [
    "It looks like that all of our algorithms showed acceptable F1 score results on the test data, but XGBoost performed the best, showing F1 score  of 0.96. Now let's take a look at the features, affecting the model performance the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_xgb.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': best_features, \n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
